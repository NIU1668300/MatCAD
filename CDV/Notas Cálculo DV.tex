\documentclass[11pt]{article}
\RequirePackage{etex}
%\pagestyle{empty}
\usepackage[activeacute,spanish,american]{babel}
\usepackage[utf8]{inputenc}%Para usar los acentos normalmente.
\usepackage[T1]{fontenc}
% \usepackage[usenames,dvipsnames,svgnames]{xcolor}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{url}

\urlstyle{same}

\usepackage[makestderr]{pythontex}
% \restartpythontexsession{\thesection}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

\usepackage{tkz-base}
\usepackage[framemethod=TikZ]{mdframed}
\usepackage[most]{tcolorbox}
\usepackage{helvet, amssymb,amsmath,latexsym}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{textcomp}
\usepackage{multienum}
\usepackage[inline,shortlabels]{enumitem}
\usepackage{multicol}
% \usepackage{gensymb}
\providecommand{\norm}[1]{\left\lVert #1 \right \rVert}
\providecommand{\abs}[1]{\left\lvert #1\right\rvert}
\usepackage{color,soul}%permite texto y subrayar en color.
\input{/home/samuel/Documents/Latex/Colores.tex}
% \usepackage[pdftex]{graphicx}
%Dimensiones
\usepackage[a4paper,left=2cm,right=1.5cm, top=1.5cm, bottom=3cm,includehead]{geometry}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Nombres de conjuntos y comandos propios.
\providecommand{\norm}[1]{\left\lVert #1 \right \rVert}
\providecommand{\abs}[1]{\left\lvert #1\right\rvert}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\I}{\mathbb{I}}
% \usepackage{esvect}
% \renewcommand{\vec}{\vv}
 \usepackage{pgf,tikz}
\usetikzlibrary{arrows.meta,arrows}
\usetikzlibrary{shadows}
\usetikzlibrary{shapes}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{shapes.multipart}
\usetikzlibrary{chains}
\usetikzlibrary{scopes}
\usetikzlibrary{matrix}
\usetikzlibrary{positioning,automata,calc}
 %\usepackage{framed}
 %\usepackage[framed, amsthm,thmmarks,thref]{ntheorem}
 %\usepackage{tkz-tab,tkz-euclide,tkz-fct,tkz-linknodes}
 \usepackage{tkz-tab,tkz-euclide}
% \usetkzobj{all}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Cajas de colores
%
\input{/home/samuel/Documents/Latex/ColorBoxes}
\input{/home/samuel/Documents/Latex/Exercises}
%Ecuaciones resaltadas
% \usepackage[overload,ntheorem,reqno]{empheq}
%\input{/home/samuel/Documents/Latex/Ambientes-teoremas}
 \theoremstyle{plain}
 \renewcommand{\qedsymbol}{\makebox[7.7778pt][c]{\rule{1ex}{1ex}}}
 \newtheorem*{demo}{Demostración}
 \input{/home/samuel/Documents/Latex/TeoremasEnumerados}
\usepackage{hyperref}
\hypersetup{
    % bookmarks=false,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in Acrobat?s bookmarks
    pdftoolbar=true,        % show Acrobat?s toolbar?
    pdfmenubar=true,        % show Acrobat?s menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={Teoria de Cálculo DV},    % title
    pdfauthor={Samuel Ortega Cuadra},     % author
    pdfsubject={},   % subject of the document
    pdfcreator={Hecho con \LaTeX},   % creator of the document
    pdfproducer={ps2pdf}, % producer of the document
    pdfkeywords={} {} {}, % list of keywords
    pdfnewwindow=true,      % links in new window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=naranja,          % color of internal links
    citecolor=violeta,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}


\setcounter{secnumdepth}{4} %controla la profundidad de la numeración


\title{Notas Programación}
\author{Samuel Ortega Cuadra}
\input{/home/samuel/Documents/Latex/messages}

\addto\captionsamerican{%
  \renewcommand{\contentsname}%
    {Índice}%
}

\begin{document}
    \begin{center}
        \huge{Teoría de Cálculo de Diversas Variables. 1º de Carrera}
    \end{center}
    \tableofcontents
    \newpage
    \section{Introducción} % (fold)
    \label{sec:introducción}
        En esta asignatura se continuará con lo explicado en la asignatura de Cálculo en una Variable, expandiendo la integración, series y un apartado de topología en varias dimensiones.

        La asignatura está dividida en 2 Parciales (40\% cada uno) Un 15\% de las prácticas y un 5\% de la nota de los lliuraments. \textbf{No hay nota mínima}, solo es necesario que la ponderación de por encima de 5. Al final de curso en el caso de no haber aprobado la asignatura se realizará un examen de recuperación que incluirá todo el contenido del curso. 
    % section introducción (end)
    \section{Espacio Euclídeo} % (fold)
    \label{sec:espacio_euclídeo}
        El Espacio Euclídeo es el espacio $\mathbb{R}^n = {(x_{1},x_{2},...,x_{n}) \text{ donde todos los $x$ pertenecen a } \mathbb{R}}$

        Por ejemplo, el plano cartesiano es un espacio euclídeo $\mathbb{R}^2$
        \subsection{Operaciones} % (fold)
        \label{sub:operaciones}
            Vectores de ambos espacios pueden sumarse entre sí sumando componente a componente:
            \begin{equation}
                (x_{1},...,x_{n}) + (y_{1},...,y_{n}) = (x_{1}+y_{1},...,x_{n}+y_{n})
            \end{equation}
        Si se multiplica por un número real ($\lambda$) se multiplican todos sus componentes:
            \begin{equation}
                \lambda (x_{1},...,x_{n}) = (\lambda x_{1},...,\lambda x_{n})
            \end{equation}
        Pero sin duda la operación más importande en un espacio euclídeo es el \textbf{Producto escalar de dos vectores}. Si tenemos dos vectores x e y pertenecientes a $\mathbb{R}^n$:
            \begin{equation}
                <x,y> = x_1 \cdot y_1 + \cdots + x_n \cdot y_n
            \end{equation}
        Las propiedades de este producto escalar son:
            \begin{itemize}
                \item $<x+z, y> = <x,y> + <z,y>, \ x,y,z \in \R^n$

                \item $<\lambda x, \mu y> = \lambda \mu <x,y> x,y \in \R^n$
                \item $ \text{La Desigualdad de Cauchy-Schwarz:}< x, y > \ \le \  <x,x>^{1/2} \cdot <y,y> ^ {1/2} x,y \in \mathbb{R}^n$
            \end{itemize}

            \subsubsection{Demostración de la Desigualdad de Cauchy-Schwarz} % (fold)
            \label{subsub:demostración_de_la_desigualdad_de_cauchy_schwarz}
                Siendo t un número Real
                \begin{equation}
                    \begin{aligned}
                            0 \ \le \ <x+ty, x +ty> & = <x,x> + t^2 <y,y> + t<x,y> + t<y,x>\\
                           & = <x,x> + t^2<y,y> + 2t<x,y>\\
                    \end{aligned}
                \end{equation}
                Por lo tanto el polinomio es:
                \begin{equation}
                    \begin{aligned}
                            P(t) & = <x,x> + t^2<y,y> + 2t<x,y>\\
                    \end{aligned}
                \end{equation}
                Es positivo para todo t pertenciente a los números reales\\
                Luego el discriminante es menor o igual que 0
                \begin{equation}
                    \begin{aligned}
                            <x,y>^2 - <y,y> <x,x> \le 0 \  es\ decir\ <x,y>^2 = <x,x><y,y>
                    \end{aligned}
                \end{equation}
            % subsubsection demostración_de_la_desigualdad_de_cauchy_schwarz (end)

            La \textbf{norma} de x perteneciente a $\R ^n$ es $\|x\| = <x,x> ^{1/2} = \sqrt{x_1^2+x_2^2+...+x_n^2}$  que corresponde a la distancia del punto x al origen.
            Es decir, que según la desigualdad de Cauchy-Schwarz $<x,y> \le \|x\| \cdot \|y\|$ \\

            Observamos que si dividimos el producto escalar por el producto de las normas siempre nos queda un valor entre 0 y 1. Este valor es el coseno del ángulo que forman los dos vectores.

            La distancia entre dos puntos se calcula hayando la norma del vector resultante de la resta entre los dos. Las propiedades de la norma son:
            \begin{itemize}
                \item $\|x\| \ge 0$ para todo $x \in \R^n$. Además $\|x\|=0$ si y solo si $x = (0,...,0)$
                \item Si $\lambda \in R$, entonces $\|\lambda x\| = |\lambda|\cdot\|x\|$ para todo $x \in \R^n$
                \item \textbf{Desigualdad Triangular:} $\|x+y\| \le \|x\| + \|y\|$ para todo $x \in \R^n$
            \end{itemize}
            \subsubsection{Demostración de la Desigualdad Triangular} % (fold)
            \label{subsub:demostración_de_la_desigualdad_triangular}
                \begin{equation}
                    \begin{aligned}
                        \|x+y\|^2 & = <x+y,x+y> \\ 
                        & = <x,x> + <y,y> + <x,y> + <y,x> \\
                        & = \|x\|^2 + \|y\| ^2 + 2 <x,y> \\
                        & \le \|x\|^2 + \|y\|^2 + 2\|x\|\cdot \|y\| \text{ (Aplicando la desigualdad de Cauchy-Schwarz)}\\
                        & = (\|x\| + \|y\|)^2
                    \end{aligned}
                \end{equation}
            %subsubsection desigualdad_Triangular (end)
        % subsection operaciones (end)
        \subsection{Otras coordenadas de R² y R³ } % (fold)
        \label{sub:otras_coordenadas_de_r_y_}
            \subsubsection{Coordenadas Polares en R²} % (fold)
            \label{subsub:coordenadas_polares_en_r2}
                Están formadas por un radio ($r$) que corresponde a la distancia desde el origen y un ángulo ($\theta$) que corresponde al ángulo que se debe girar el eje real positivo hasta llegar al punto (sentido antihorario). \\ Para hacer el paso de coordenadas cartesianas a coordenadas polares tomaremos que: \[r = \text{distancia de (x,y) al origen} = \sqrt{x^2 + y^2}\]\[\theta = \text{ángulo que se debe girar el eje hor. positivo para llegar al punto} = arctan(\frac{y}{x})\]
                Y para hacer el paso inverso se haría de la siguiente forma:\[x = r\cdot cos(\theta)\]\[y = r\cdot sin(\theta)\]
                    
            % subsubsection coord polar en r2 (end)
            \subsubsection{Coordenadas Cilíndricas en R³} % (fold)
            \label{subsub:coordenadas_ciĺindricas_en_r3}
                Sean $(x,y,z) \in \R^3$ las coordenadas de un punto en $\R^3$, las coordenadas cilíndricas son $(r,\theta,z)$ donde $(r,\theta)$ corresponde al punto $(x,y)$ en coordenadas polares. De esta forma se tomaría el círculo de radio $r$ en el plano $x,y$ y la altura ($z$), de ahí el nombre de coordenada cilíndrica. Las coordenadas en polares $(r,\theta)$.
            %subsubsection coord_cil_en_r3
            \subsubsection{Coordenadas Esféricas en R³} % (fold)
            \label{subsub:coordenadas_esfericas_en_r3}
                En las coordenadas esféricas, tomando un punto $(x,y,z)$, las coordenadas esfericas son $(\rho,\varphi,\theta)$ donde \[\rho = \text{distancia del punto al origen} = \|(x,y,z)\| = \sqrt{x^2 + y^2 + z^2} \] \[\varphi = \text{ángulo que debe moverse el eje verical para llegar al punto} \in (0,\pi)\] \[\theta = \text{ángulo que se debe mover el eje real positivo hasta alcanzar el punto (x,y,0) }\]
                De aquí se deduce que:
                \[z = \rho \cdot cos(\varphi)\]
                \[sin(\varphi) = \frac{r}{\rho} \tag{Siendo r la distancia de la proyección en el plano (x,y)}\]
                \[x = \rho \cdot sin(\varphi) \cdot cos(\theta) \]
                \[y = \rho \cdot sin(\varphi) \cdot sin(\theta)\]

                En estas coordenadas, se toma una esfera de radio $\rho$ y luego se indica en que posición de la superficie de esa esfera se encuentra el punto, de ahí el nombre de coordenadas esféricas. 
            %subsubsection coord_esf_en_r3    
        % subsection otras_coordenadas_de_r_y_ (end)
    % section espacio_euclídeo (end)
    \section{Topología} % (fold)
    \label{sec:topología}
        \subsection{Interior de un Conjunto} % (fold)
        \label{sub:interior_de_un_conjunto}
            Sea $x_0 \in \R^n$ y $r > 0$, denotamos como $B(x_0,r) = \text{puntos x de $\R^n$ a distancia de $x_0$ menor que r} = \{x \in \R^n: \|x-x_0\|< r \}$. Esto se llama \textbf{bola abierta} centrada a $x_0$ y de radio $r$, ya que los puntos de la superficie de la bola no se consideran dentro. \\

            Siendo $A \subset \R^n$, definimos que $A^{\mathrm{o}}$, el interior del conjunto $A$ es $x\in \R^n$ tal que exista un $r>0$ de forma que $B(x,r) \subseteq A$
        % subsection interior_de_un_conjunto (end)
        \subsection{Conjunto abierto} % (fold)
        \label{sub:conjunto_abierto}
            Un conjunto $A$ se considera un conjunto abierto si $ A = A^{\mathrm{o}}$. Se puede pensar como aquellos conjuntos que no incluyen su frontera. Por ejemplo, si tuvieramos un conjunto $A = (a,b)$, este conjunto sería abierto ya que $(a,b) = \{ x \in \R \text{ tal que hay un intervalo centrado a $x$ contenido dentro de $(a,b)$}\}$  
        % subsection conjunto_abierto (end)
        \subsection{Conjunto cerrado} % (fold)
        \label{sub:conjunto_cerrado}
            Sea $A \subset \R ^n$, definimos la \textbf{adherencia del conjunto A} como $\overline{A} = \{x\in \R^n \text{ tal que } B(x,r)\cap A \ne \emptyset \text{ para todo } r>0\}$. Por este motivo sabemos con seguridad que $A \subseteq \overline{A}$. Por ejemplo, si se tuviera un intervalo $(a,b)$, adherencia de este intervalo sería el intervalo $[a,b]$.\\

            Observamos que si $x \notin [a,b]$ entonces $x \notin \overline{(a,b)}$, pues para radios más pequeños que la distancia entre $x$ y $(a,b)$, la intersección es $\emptyset$.\\

            Decimos que un conjunto es un \textbf{conjunto cerrado} si $\overline{A} = A$. De esta forma nos encontramos con un teorema:
            %Pendiente revisión de teoremas
            \begin{center}
                \textit{Sea $A \subset \R^n$ entonces $A$ es abierto $\Leftrightarrow$ su complementario es cerrado}
            \end{center}
        % subsection conjunto_cerrado (end)
        \subsection{Frontera de un conjunto} % (fold)
        \label{sub:frontera_de_un_conjunto}
            Sea $A \subset \R^n$, definimos la frontera de $A$ como $fr(A) = \overline{A} \backslash  A^{\mathrm{o}}$, es decir la parte que contiene $\overline{A}$ pero no $A^{\mathrm{o}}$
        % subsection frontera_de_un_conjunto (end)
        \subsection{Conjunto acotado y conjunto compacto} % (fold)
        \label{sub:conjunto_acotado_y_conjunto_compacto}
            Un conjunto $A \subset \R^n$ se considera \textbf{acotado} si existe $M>0$ tal que $A\subseteq \text{Bola centrada al origen de radio M}$. Por ejemplo, una recta a en $\R^2$ no está acotado, pero un cubo en $\R^3$ sí.

            Si ademaś de acotado el conjunto es cerrado se le denomina \textbf{conjunto  compacto.}
            % subsection conjunto_acotado_y_conjunto_compacto (end)
    % section topología (end)
    \section{Límites de funciones y Continuidad} % (fold)
    \label{sec:límites_de_funciones_y_continuidad}
        En este apartado, estudiaremos funciones que vayan desde $\R^n$ a $\R^m$:
        \[f: \R^n \longmapsto \R^m \]
        \[x=(x_1,x_2,...,x_n) \rightarrow (f_1(x),f_2(x),...,f_m(x))\]
        Por ejemplo: una función que iría de $\R^2$ a $\R$ es $f(x,y) = cos(x+y)e^{-x}$, mientras que una función que vaya desde $\R$ hasta $\R^3$ podría ser $f(t) = (e^{-t}, cos(t), sin(t))$. Cuando trabajamos con funciones que trabajan con más de una variable llega un punto en el que no pueden representarse de forma sencilla, ya que las dimensiones necesarias para representar la función serían $n+m$, por lo que primero definiremos el concepto de gráfico.
        \begin{center}
            \textbf{Definición:} Un \textbf{gráfico} se define como \[Graf(f) = \{(x,f(x)): x \in Dominio \ de \ f(x) \} \subset \R^{n+m} \rightarrow \text{tiene $n+m$ componentes}\]
        \end{center}
        Esta $x$ que aparece en la definición de gráfico no se refiere a la componente $x$, sino al vector del espacio $\R^n$ que se introduce en la función (Puede escribirse si resulta más fácil como $\vec{x}$). Por ejemplo, si tuvieramos que escribir el gráfico de $f(x,y) = x^2 + y ^2$ sería:
        \[Graf(f) = \{(x,y,x^2 + y^2)\} \subset \R^3\]
        Tras esto será necesario definir el concepto de conjunto de nivel:
        \begin{center}
            \textbf{Definición:} Un \textbf{conjunto de nivel} o \textbf{nivel c} de una función $f$ es el conjunto de $\{\vec{x} \in \R^n \text{ tal que } f(\vec{x}) = c \}$
        \end{center}
        Aplicando este concepto a la función anterior, un conjunto de nivel c sería: \[= \{(x,y) : x^2+y^2 = c\} = \{(x,y): dist((x,y),(0,0)) = \sqrt{c}\} = \text{circunferencia de centro $(0,0)$ y radio $\sqrt{c}$}\]

        \subsection{Límite de una sucesión en un espacio n-dimensional} % (fold)
        \label{sub:límite_de_una_sucesión_en_un_espacio_n_dimensional}
            Sea $\{x_k\}$ una sucesión de puntos de $\R^n$, definimos su límite como:
            \begin{equation}
                \lim_{k\to\infty} x_k = L \text{ si para todo } \varepsilon > 0, \text{ existe } k_0=k_0(\varepsilon)>0\text{ tal que } \norm{x_k - L} = dist(x_k,L)<\varepsilon
            \end{equation}
            Es decir, $x_k$ pertenece a una bola de centro $L$ y radio $\varepsilon$ si $k\ge k_0$
        % subsection límite_de_una_sucesión_en_un_espacio_n_dimensional (end)
        \subsection{Límte de una función en n dimensiones} % (fold)
        \label{sub:límte_de_una_función_en_n_dimensiones}   
            El límite de una función que va de $\R^n$ a $\R^m$ lo definimos como:
            \begin{equation}
                \lim_{\vec{x}\to\vec{x_0}} f(x) = L \text{ si para todo } \varepsilon>0 \text{ existe } \delta = \delta(\varepsilon) > 0 \text{ tal que } \norm{f(\vec{x}) - L}<\varepsilon \ si \ 0<\norm{\vec{x}-\vec{x_0}}<\delta
            \end{equation}
            Es decir, se cumple el límite si cuando $x$ se acerca a $x_0$, $f(\vec{x})$ se acerca a $L$. Por ejemplo, tomando la función $f(x,y,z) = (e^{-y-z}x^2,sin(xy)+z^2+1)$, si cogieramos el límite cuando $(x,y,z)$ tiende a $(0,0,0)$, obtendríamos como resultado $L = (0,1)$.\\

            Estos límites presentan unas propiedades similares a los límites en una variable. Si tomaramos dos límites $\lim_{x\to x_0} f(x) = L_1$ y $\lim_{x\to x_0} g(x) = L_2$, las propiedades serían:
            \begin{enumerate}[label = \Alph*]
                \item El límite de la suma de funciones es la suma de los límites \[\lim_{x\to x_0} (f(x)+g(x)) = L_1 + L_2\]
                \item El límtie del producto de funciones es el producto de los límties \[\lim_{x\to x_0} f(x)g(x) = L_1 \cdot L_2\]
                \item Si $L_2 \ne 0$, entonces \[\lim_{x\to x_0} = \frac{f(x)}{g(x)} = \frac{L_1}{L_2}\]
                \item \textbf{Límites direccionales:} Sea $f$ una función que va de $\R^2$ a $\R$: \[\lim_{(x,y) \to (0,0)} f(x,y) = L \Rightarrow \lim_{t \to 0} f(t,mt) = L \text{ con L independiente de $m$}\]
                Sin embargo, esta dependencia no ocurre en el sentido contrario, solo funciona de esta forma. 
            \end{enumerate}
            Si aplicamos los limites direccionales a un ejemplo quedaría de la siguiente forma:
            \begin{equation}
                \begin{aligned}
                    \lim_{(x,y) \to (0,0)} \frac{x^3 + e^x y^2}{x^2 + y^2} & = \frac{0}{0}\\
                    \text{Aplicando los límites direccionales:}\\
                    \lim_{t\to 0} f(t,mt) & = \lim_{t \to 0} \frac{t^3+e^t(mt)^2}{t^2 + (mt)^2}\\
                    & = \lim_{t \to 0} \frac{t + e^tm^2}{1 + m^2}\\
                    & = \frac{m^2}{1+m^2} \rightarrow \text{Depende de m}\\
                \end{aligned}
            \end{equation}
            Por lo tanto, el límite original no existe. Sin embargo, podemos encontrarnos con casos en los que $\lim_{t\to 0} f(t,mt)$ exista y no sea dependiente de m. En esos casos, no podemos decir nada, pues es posible que el límite original no exista aún así.

        % subsection límte_de_una_función_en_n_dimensiones (end)
        \subsection{Continuidad de una función en n dimensiones} % (fold)
        \label{sub:continuidad_de_una_función_en_n_dimensiones}
            Sea $U \subset \R^n $ abierto y sea $f:U \rightarrow \R$ y sea $x_0 \in U$.
            \textbf{Definición:} Decimos que $f$ es continua en $x_0$ si \[\lim_{x\to x_0} f(x) = f(x_0)\]
            Ya que $x_0 \in U_{abierto}$, entonces existe una bola centrada en $x_0$ contenida en $U$ y por tanto $f$ está definida en el borde de $x_0$. 
            \begin{itemize}
                \item Si tenemos $f:\R^n \rightarrow \R$, entonces $f= (f_1,f_2,...,f_m)$ donde cada $f_j: \R^n \rightarrow \R$. Entonces, diremos que f es continua en $x_0$ si todas las $f_j$ son continuas en $x_0$
                \item Decimos que f es continua en un conjunto abierto $U \subset \R^n$ si es continua en todos los puntos de $U$.
            \end{itemize}
            \subsubsection{Propiedades de la continuidad} % (fold)
            \label{subsub:propiedades_de_la_continuidad}
                Sean $f,g: U \rightarrow \R$ continuas en $x_0 \in U$
                \begin{enumerate}[label = \Alph*]
                    \item Entonces $f+g$ y $f \cdot g$ son continuas en $x_0$
                    \item Si $g(x_0) \ne 0$, entonces $\frac {f}{g}$ es continua en $x_0$
                    \item Sea $h:\R\rightarrow\R$ continua en el punto $f(x_0)$, entonces $h \circ f$ es continua en $x_0$
                \end{enumerate}
                Es importante tener en cuenta que la continuidad es una propiedad local, se observa un punto $x_0$ y sus alrededores pero no se observa toda la función. Para poder observar la continuidad en todo el espacio tendremos que hacernos valer de las propiedades mencionadas anteriormente. Por ejemplo, pongamos que tenemos la siguiente función:
                \begin{equation}
                    f(x,y) = 
                    \begin{cases}
                        (x^2 + y^2)sin(\dfrac{1}{x^2+y^2}) \text{ si } (x,y)\ne(0,0)\\ \\ 0 \text{ si } (x,y) = (0,0)
                    \end{cases}
                \end{equation}
                De esta ecuación distinguimos dos casos:
                \begin{itemize}
                    \item Si $(x_0,y_0) \ne (0,0)$, $f$ es continua en $(x_0,y_0)$ ya que es producto, composición y división de funciones continuas con denominador distinto de 0 en el punto $(x_0,y_0)$
                    \item ¿$f$ es continua en $(0,0)$? $\Leftrightarrow \lim_{(x,y)\to(0,0)} f(x,y) = f(0,0) = 0$
                    \[\Leftrightarrow \lim_{(x,y)\to(0,0)} (x^2 + y^2)sin(\frac{1}{x^2 + y^2}) = 0 \]
                    Esto se cumple empleando el teorema del sandwich, ya que como $\abs{sin(t)} \le 1 \; \forall t\in\R$:
                    \[0 \le \abs{(x^2+y^2)sin(\frac{1}{x^2+y^2})}\le \abs{x^2 + y^2} \rightarrow 0\]
                    Luego es continua.
                \end{itemize}
            % subsubsection propiedades_de_la_continuidad (end)
        % subsection continuidad_de_una_función_en_n_dimensiones (end)
        \subsection{Teorema de Weierstrass} % (fold)
        \label{sub:teorema_de_weierstrass}
            Sea $K\subset \R^n$ compacto y $f:K\rightarrow \R$ continua. Entonces $f$ tiene un máximo y un mínimo en $K$, es decir
            \begin{equation}
                 \exists x_{MAX} \in K \ y \ x_{MIN} \in K \text{ tal que } f(x_{MIN})\le f(x) \le f(x_{MAX}) \; \forall x \in K
             \end{equation} 
        
        % subsection teorema_de_weierstrass (end)
        \subsection{Propiedad Útil: Desigualdad de la suma de cuadrados} % (fold)
        \label{sub:propiedad_útil_desigualdad_de_la_suma_de_cuadrados}
            Una propiedad que puede resultar muy útil a la hora de realizar límites es la siguiente:
            \begin{equation}
                x^2 + y^2 \ge 2\abs{x}\cdot\abs{y}
            \end{equation}
            Esta propiedad se deduce de la desigualdad entre la media aritmética, obtenida a partir de la suma de todos los términos dividido entre el número de términos sumados, y la media geométrica, obtenida a base de multiplicar todos los términos y hacer la raiz enésima siendo n el número de términos. Si tomamos ambas medias, la media aritmética siempre será más grande que la geométrica, de ahí obtenemos esta desigualdad.
        % subsection propiedad_útil_desigualdad_de_la_suma_de_cuadrados (end)
    % section límites_de_funciones_y_continuidad (end)
    \section{Diferenciabilidad} % (fold)
    \label{sec:diferenciabilidad}
        Pongamos que tenemos un $U \in \R^n$ abierto y sea $f:U \rightarrow \R$. Definimos:
        \begin{equation}
            \frac{\partial f}{\partial x_i} (a) = \lim_{h\to 0} \frac{f(a +h\cdot e_i) - f(a)}{h} \; \text{(si existe)} \equiv 
        \end{equation}
        Donde: \[e_i = (0,...,0,\overbrace{1}^{i},0,...,0)\]
        De esta forma, todas las variables diferentes se mantienen fijas y se deriva respecto a $x_i$

        \textbf{Ejemplo:}
        \[f(x,y,z) = e^ x cos(y) -sin(z)\]
        \[\frac{\partial f}{\partial x} = cos(y) \cdot e^x \; \text{(Aquí cos(y) actúa como constante)}\]
        \[\frac{\partial f}{\partial y} = e^x \cdot (-sin(y))\]
        \[\frac{\partial f}{\partial z} = - cos(z)\]

        \subsection{Continuidad en derivadas parciales} % (fold)
        \label{sub:continuidad_en_derivadas_parciales}
            Hay funciones tales que $\dfrac{\partial f}{\partial x_i}$ existen para todo $i$ pero $f$ no es continua. Por ejemplo: \\
                \begin{equation}
                    f(x,y) =
                    \begin{cases}
                        \frac{xy}{x^2 + y^2} &\text{ si } (x,y)\ne(0,0)\\
                        0 &\text{ si } (x,y) = (0,0)
                    \end{cases}
                \end{equation}
            $\dfrac{\partial f}{\partial y} (x,y)$, $\dfrac{\partial f}{\partial y} (x,y)$ existen para todo $(x,y) \in \R^2$, ya que pueden calcularse todos los valores en los que $x_0 \ne 0$ y $y_0 \ne 0$, y para los casos en los que $x_0 = 0$ o $y_0 = 0$ da 0. \\

            Sin embargo, $f$ no es continua en $(0,0)$, ya que el límite cuando $(x,y)$ tiende a 0 no existe.
            \[\lim_{\substack{x \to 0 \\ y \to mx}} f(x,mx) = \lim_{x \to 0} \frac{mx^2}{x^2 + m^2x^2} = \frac{m}{1 + m^2} \rightarrow \text{Depende de la recta}\]
        % subsection continuidad_en_derivadas_parciales (end)
        \textbf{NOTACIÓN:}
        \begin{equation}
            \nabla f(a) = \left( \frac{\partial f}{\partial x_1}(a), \frac{\partial f}{\partial x_2}(a), ... , \frac{\partial f}{\partial x_n}(a)\right) 
        \end{equation}
        Recordemos que si $f:\R \rightarrow \R$ y $a\in \R$, f es derivable en el punto a $\Leftrightarrow$
        \[\Leftrightarrow \lim_{h \to 0} \frac{f(a+h) - f(a)}{h} = f'(a) \Leftrightarrow \lim_{h \to 0} \frac{f(a+h) - f(a) - f'(a)h}{h} = 0\]
        \[\Leftrightarrow \lim_{h\to 0} \frac{f(a+h) - (f(a)+f'(a)h)}{h} = 0 \xLeftrightarrow{x=a+h} \lim_{x\to a} \frac{f(x) - (f(a)+ f'(a)(x-a))}{x-a} = 0\]
        \textbf{Definición:} Sea $U \subset \R^n$ abierto, $a \in U$ y $f:U\rightarrow \R$. Suponemos que $\nabla f(a)$ existe. Decimos que $f$ es diferenciable en el punto $a$ si:
        \begin{equation}
            \lim_{x \to a} \frac{\abs{f(x) - (f(a) + \nabla f(a)\cdot (x-a))}}{\norm{x-a}} = 0
        \end{equation}
        Observemos que $x_{n+1} - f(a) = \nabla f(a)\cdot(x-a)$ es el plano tangente a la gráfica en el punto $(x,f(a))$.\\
        \textbf{Propuesta:} Si f es diferenciable en el punto a, entonces f es continua en el punto a.\\
        \textbf{Demostración:}
            Utilizando Cauchy-Schwartz:
            \[\abs{\nabla f(a) \cdot (x-a)} \le \norm{\nabla f(a)} \cdot \norm{x-a}\]
            Entonces:
            \[\frac{\abs{\nabla f(a)\cdot (x-a))}}{\norm{x-a}} \le \norm{\nabla f(a)}\]
            Como f es diferenciable en el punto a:
            \[\frac{\abs{f(x)-f(a)}}{\norm{x-a}} \le \norm{\nabla f(a)} + \varepsilon \text{ si } \norm{x-a} \text{ es muy pequeño}\]
            Por tanto:
            \[\lim_{x \to a} \abs{f(x)-f(a)} = 0\]
            Y eso implica que f es continua en el punto a.\\
        \textbf{Propuesta:} Sean $f,g$ funciones diferenciables en el punto a entonces:
        \begin{itemize}
            \item $f\pm g$ es diferenciable en $a$
            \item $f \cdot g$ es diferenciable en $a$
            \item Si $g(a)\ne 0$, entonces $\dfrac{f}{g}$ es diferenciable en $a$ 
        \end{itemize}
        \textbf{TEOREMA:}
        \begin{center}
            \textit{Sea $f$ una función tal que $\dfrac{\partial f}{\partial x_i}$ son funciones continuas en un abierto $U \subset \R^n$ y $i=1,...,n$, entonces $f$ es diferenciable en $U$, es decir, f es diferenciable en todos los puntos del abierto $U$}
        \end{center}
        \textbf{Definición:} Sea $U \subset \R^n$ abierto, $a \in U$ y $f:U\rightarrow \R$. Sea $\vec{v}\in\R^n$,$\norm{\vec{v}} = 1$. Definimos:
        \begin{equation}
            D_{\vec{v}} f(a)= \lim_{h\to 0} \frac{f(a +h\vec{v}) -f(a)}{h}
        \end{equation} 
        Esta nomenclatura corresponde a la derivada en la dirección $\vec{v}$.\\

        \textbf{Propuesta:} \[D_{\vec{v}} f(a) = \nabla f(a) \cdot \vec{v}\]
        \textbf{Demostración:} Sea $\vec{e_i} = (0,0,...,0,\overbrace{1}^{i},0,...,0,0), i=1,...,n$, tenemos:
        \[\vec{v}\equiv \sum_{i=1}^{n} v_i \vec{e_i}\]
        \[ \frac{f(a +h\vec{v}) -f(a)}{h} =  \frac{f(a +\sum_{i=1}^{n} hv_i \vec{e_i}) -f(a)}{h}(n=2)\]
        \[= \frac{f(a + hv_1\vec{e_1} +hv_2\vec{e_2}) - f(a + hv_1\vec{e_1})}{h} + \frac{f(a + hv_1\vec{e_1}) -f(a)}{h}\]
        \[= \frac{f(a + hv_1\vec{e_1} +hv_2\vec{e_2}) - f(a + hv_1\vec{e_1})}{hv_2}\cdot v_2 + \frac{f(a + hv_1\vec{e_1}) -f(a)}{hv_1}\cdot v_1\]
        Cuando $h$ tiende a $0$:
        \[\dfrac{\partial f}{\partial x_1}(a) \cdot v_1 + \dfrac{\partial f}{\partial x_2}(a)\cdot v_2 = \nabla f(a) \cdot \vec{v}\]
        \textbf{Corolario:}
        \begin{enumerate}[label= \Alph*]
            \item \[\abs{D_{\vec{v}} f(a)} \le \norm{\nabla f(a) \cdot \vec{v}} ;\; \forall \vec{v} \in \R^n, \norm{\vec{v}}=1\]
            \item La dirección $\vec{v}$ de máximo crecimiento (decrecimiento) de la función $f$ en el punto $a$ es $\vec{v} = \dfrac{\nabla f(a)}{\norm{\nabla f(a)}}$ ($\vec{v} = - \dfrac{\nabla f(a)}{\norm{\nabla f(a)}}$)
        \end{enumerate}
        \subsection{Funciones que devuelven un resultado en m dimensiones} % (fold)
        \label{sub:funciones_que_devuelven_un_resultado_en_m_dimensiones}
            Sea $U \subset \R^n$ abierto y consideramos $f:U \rightarrow \R^m$. $\R^n \ni \vec{x} \rightarrow f(\vec{x}) = (f_1(\vec{x}),f_2(\vec{x}),...,f_m(\vec{x}))$. Diremos que $f$ es diferenciable en el punto $a$ si $f_a,f_2,...,f_m$ son diferenciables en el punto $a$.
            \[(\Leftrightarrow \lim_{x\to a} \frac{\abs{f_k(x) -f(a) - \nabla f_k(a)\cdot(x-a)}}{\norm{x-a}}=0; k = 1,...,m \Leftrightarrow \lim_{x\to a} \frac{\abs{f(x) -f(a) - Df(a)\cdot(x-a)}}{\norm{x-a}}=0\]
            $Df(a)$ corresponde a la \textbf{matriz diferencial} de $f$. Esta matriz posee los resultados de las derivadas parciales de cada función (filas) y cada variable(columnas):
            \begin{equation}
                Df(a) = 
                \begin{pmatrix}
                    \frac{\partial f_1}{\partial x_1}(a)&\frac{\partial f_1}{\partial x_2}(a)&\frac{\partial f_1}{\partial x_3}(a)&\cdots & \frac{\partial f_1}{\partial x_n}(a)\\
                    \vdots&&&&\vdots\\
                    \frac{\partial f_m}{\partial x_1}(a)&\frac{\partial f_m}{\partial x_2}(a)&\frac{\partial f_m}{\partial x_3}(a)&\cdots & \frac{\partial f_m}{\partial x_n}(a)

                \end{pmatrix}
            \end{equation}
            \textbf{Regla de la Cadena:} Sea $\R^n \supset U \xrightarrow{f} \R^m \xrightarrow{g} \R^k$. Sea $a \in U$ y suponiendo que $f$ es diferenciable en el punto $a$ y $g$ es derivable en el punto $f(a)$. Entonces $g \circ f$ es diferenciable en el punto $a$ y:
            \[D(g\circ f)(a) = D(g)(f(a)) \cdot D(f)(a)\]

        % subsection funciones_que_devuelven_un_resultado_en_m_dimensiones (end)
    % section diferenciabilidad (end)
    \section{Curvas y Superficies} % (fold)
    \label{sec:curvas_y_superficies}
        Una curva $\gamma$ en $\R^n$ es una aplicación $\gamma:[a,b] \rightarrow \R^n$ continua.
        \[t \rightarrow \gamma(t) = (\gamma_1(t), \gamma_2(t),...,\gamma_n(t))\]
        Ejemplo:
        \[[0,2\pi] \xrightarrow{\gamma} \R^2\]
        \[t \rightarrow (Acos(t), Bsin(t))\]
        Esta es una curva en $\R^2$ que corresponderá a una elipse. El \textbf{vector tangente} de una curva $\gamma$ en un punto t es aquel vector con la misma pendiente que la curva $\gamma$ en ese punto y que parte de $\gamma(t)$ en dirección $b$, pues siempre tiene que ir en el sentido de la curva. Para hallar este vector observaremos $\gamma(t+h)$. Usando este nuevo punto y el punto original definiremos el vector como:\[\lim_{h\to 0} \frac{\gamma(t+h)-\gamma(t)}{h} = \gamma'(t) =(\gamma'_1(t), \gamma'_2(t),...,\gamma'_n(t))\]
        Aplicando esto a nuestro ejemplo anterior:
        \[\gamma'(t) = (-Asin(t),Bcos(t)) \Rightarrow \gamma'(\pi/4) = (\frac{-A\sqrt{2}}{2},\frac{B\sqrt{2}}{2})\]
        Este sería el vector tangente a la elipse en el punto $\gamma(\pi/4)$
        \subsection{Longitud de una curva} % (fold)
        \label{sub:longitud_de_una_curva}
            Sea $\gamma:[a,b] \rightarrow \R^2$, entonces $a = t_0 < t_1 < t_2 < \cdots < t_{N-1} < t_N = b$. Luego:
            \[\text{Longitud de la poligonal} = \sum_{i=1}^{N} \text{Longitud del segmento entre $\gamma(t_i)$ y $\gamma(t_{i-1})$} \]
            Para hallar la distancia de cada segmento podemos usar pitágoras, pues usando cada una de las componentes nos queda un triángulo rectángulo:
            \[\gamma(t_{i-1}) = (\gamma_1(t_{i-1}), \gamma_2(t_{i-1}))\; ; \; \gamma(t_{i}) = (\gamma_1(t_{i}), \gamma_2(t_{i}))\]
            \[h^2 = c_x^2 + c_y^2 \; ; \; c_x = \gamma_1(t_{i}) - \gamma_1(t_{i-1}), c_y = \gamma_2(t_{i}) - \gamma_2(t_{i-1}) \]
            Sabiendo esto:
            \begin{align}
                \text{Longitud de la poligonal} & = \sum_{i=1}^{N} \sqrt{(\gamma_1(t_{i}) - \gamma_1(t_{i-1}))^2 + (\gamma_2(t_{i}) - \gamma_2(t_{i-1}))^2}\\
                & \simeq \sum_{i=1}^{N} \sqrt{(\gamma'_1(t_{i})^2(t_i - t_{i-1})^2 + \gamma'_2(t_{i})^2(t_i - t_{i-1})^2}\\
                & = \sum_{i=1}^{n} \sqrt{\gamma'_1(t_{i})^2 + \gamma'_2(t_{i})^2}\cdot (t_i - t_{i-1})\\
                & = \sum_{i=1}^{n} \norm{\gamma'(t_i)}\cdot(t_i-t_{i-1})\rightarrow \text{si $n$ tiende a infinito} \simeq \int_{a}^{b} \norm{\gamma'(t)} dt
            \end{align}
        % subsection longitud_de_una_curva (end)
        \subsection{Superficies en 3 dimensiones} % (fold)
        \label{sub:superficies_en_3_dimensiones}
            Una superficie en $\R^3$ es $f(x,y,z) = \mathcal{C}$ donde $f$ es una función continua y $\mathcal{C} \in \R$. Por ejemplo: 
            \[x^2+2y^2+3z^2 = 6\]
            Esta superficie es una elipsoide. Efectivamente, si $z=cte.$ obtenemos $x^2+2y^2+3\mathcal{C}^2 = 6$, es decir, $x^2+2y^2 = 6-3\mathcal{C}^2$\\
            \underline{Observación:} El vector normal a la superficie $f(x,y,z)=\mathcal{C}$ en el punto $(x,y,z)$ es $\nabla f(x,y,z)$\\
            \textbf{¿Por qué?} Śea $\gamma$ una curva contenida en la superficie. Tenemos $f(\gamma(t)) = \mathcal{C}$
        % subsection superficies_en_3_dimensiones (end)
        \subsection{Polinomio de Taylor} % (fold)
        \label{sub:polinomio_de_taylor}
            Recordemos que si $f:\R \rightarrow \R$ y $x_0 \in \R$, el polinomio de Taylor de $f(x)$ en el punto $x_0$ y de grado $n$ es:
            \[P_{n,f,x_0} (x) = f(x_0) + f'(x_0) (x-x_0) + \frac{f''(x_0)}{2!}(x-x_0)^2 + \frac{f'''(x_0)}{3!}(x-x_0)^3 + \cdots + \frac{f^{n'}(x_0)}{(x-x_0)^n}\]
            Sea ahora $f:\R^3 \rightarrow \R$, el polinomio de Taylor de grado $n$ de la función $f$ en el punto $x_0$ es:
            \begin{align}
                P_{n,f,x_0}(x) = f(x_0) + & \sum_{i=1}^3 \frac{\partial f}{\partial x_i}(x_0)(x_i-x_{0,i}) + \frac{1}{2!} \sum_{i,j=1}^{3} \frac{\partial^2 f}{\partial x_i\partial x_j}(x_0) (x_i-x_{0,i})(x_j-x_{0,j})+ \cdots + \nonumber \\
                &  \frac{1}{n!} \sum_{i_1,i_2,...,i_n = 1}^{3} \frac{\partial^n f}{\partial x_{i_n} \cdots \partial x_{i_1}}(x_0)(x_{i_1} -x_{0_{i_1}})\cdots(x_{i_n}-x_{0_{i_n}})
            \end{align}

            \textbf{TEOREMA DE SCHWARZ:} \textit{Sea $f$ una función con segundas derivadas continuas. Entonces:}
            \[\frac{\partial^2f}{\partial x_j \cdot\partial x_i } = \frac{\partial^2f}{\partial x_i \cdot\partial x_j }\]

            \subsubsection{Cálculo de Polinomios de Taylor utilizando polinomios de grado 1} % (fold)
            \label{subsub:calculo_de_polinomios_de_taylor_utilizando_polinomios_de_grado_1}
            Si nos pidiesen calcular el poliomio de taylor de una función $f(x,y,z)=\dfrac{1}{1-xyz}$ en el punto $(0,0,0)$ y grado 8 podríamos emplear un polinomio de taylor de grado 1. Sabemos que:
            \[\frac{1}{1-t} = 1 + t + t^2 + t^3 + \cdots + t^n; \; t\in(-1,1)\]
            Luego si $t=xyz$, podríamos hallar el polinomio de Taylor facilmente. Lo mismo ocurre con la función $g(x,y) = e^x \cdot sin(y)$. En este caso podemos sacar facilmente el polinomio de taylor de ambas funciones por separado $(e^x$ y $sin(y))$ por lo que luego solo haría falta multiplicar ambos polinomios.\\
            % subsubsection calculo_de_polinomios_de_taylor_utilizando_polinomios_de_grado_1 (end)

            \textbf{TEOREMA DE TAYLOR:} \textit{Sea $P_k$ el polinomio de taylor de grado $k$ de la función $f$ en el punto $a$ entonces:}
            \[f(x) = P_k(x) + O(\norm{x-a}^{k+1})\]
            Es decir:
            \[\abs{f(x) - P_k(x)} \le \mathcal{C}\norm{x-a}^k+1; \; \text{Para alguna constante } \mathcal{C}>0\]

            \subsubsection{Cálculo de Polinomios de Taylor utilizando polinomios de grado 2} % (fold)
            \label{subsub:calculo_de_polinomios_de_taylor_utilizando_polinomios_de_grado_2}
                Sea $f:\R^n \rightarrow \R$ y $a\in\R^n$. El polinomio de Taylor de grado 2 en el punto $a$ es:
                \[P_{n,f,x_0}(x) = f(x_0) +  \sum_{i=1}^3 \frac{\partial f}{\partial x_i}(x_0)(x_i-x_{0,i}) + \frac{1}{2!} \sum_{i,j=1}^{3} \frac{\partial^2 f}{\partial x_i\partial x_j}(x_0) (x_i-x_{0,i})(x_j-x_{0,j})\]
                De aquí se puede considerar dos partes. El primer sumatorio, que corresponde al gradiente:
                \[\sum_{i=1}^3 \frac{\partial f}{\partial x_i}(x_0)(x_i-x_{0,i}) = \nabla f(a) \cdot (x-a)\]
                Y el segundo sumatorio, que puede expresarse en forma de matriz como ya hemos visto anteriormente:
                \begin{equation}
                    \text{Segundo Sumatorio} = (x_1-a_1,x_2-a_2,...,x_n-a_n)
                    \begin{pmatrix}
                        \frac{\partial^2 f}{(\partial x_1)^2}(a) & \frac{\partial^2 f}{\partial x_2 \partial x_1}(a) & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n}(a)\\
                        \frac{\partial^2 f}{\partial x_1 \partial x_2}(a) & \frac{\partial^2 f}{(\partial x_2)^2}(a) & \cdots & \frac{\partial^2 f}{\partial x_2 \partial x_n}(a)\\
                        \vdots & & & \\
                        \frac{\partial^2 f}{\partial x_1 \partial x_n}(a) & \frac{\partial^2 f}{\partial x_2 \partial x_n}(a) & \cdots & \frac{\partial^2 f}{(\partial x_n)^2}(a)
                    \end{pmatrix}
                    \cdot
                    \begin{pmatrix}
                        x_1-a_1 \\
                        x_2-a_2 \\
                        \vdots \\
                        x_n-a_n \\
                    \end{pmatrix}
                \end{equation}
                Esta matriz formada por las derivadas segundas es la matriz Hessiana $(Hess \; f(a))$

            % subsubsection calculo_de_polinomios_de_taylor_utilizando_polinomios_de_grado_1 (end)

        % subsection polinomio_de_taylor (end)
    % section curvas_y_superficies (end)
    \section{Extremos relativos} % (fold)
    \label{sec:extremos_relativos}
    \textbf{Definición:}Sea $f:\R\rightarrow \R$ y $x_0 \in \R$. $x_0$ es máximo relativo si $f(x_0) \ge f(x) \; \forall x \in \R^n$ con $||x-x_0|| \le \sigma$\\
    \textbf{Observación:} $x_0$ es un extremo relativo $\Rightarrow \nabla f(x_0) = (0,...,0)$\\

    \subsection{Matrices definidas positivas y negativas} % (fold)
    \label{sub:matrices_definidas_positivas_y_negativas}
        \textbf{Definición:} Sea $A$ una matriz simétrica, $A$ es definida positiva si:
        \[\lambda A \lambda^t \ge 0 \; \text{ para todo } \lambda \in \R^n \; (A\in M_{n\times n} (\R))\]
        Es decir:
        \begin{equation}
            (\lambda_1, \lambda_2,... ,\lambda_n)\cdot
            \begin{pmatrix}
                a_{11} & a_{21} & \cdots& a_{n1}\\
                a_{12}&&&\\
                \vdots&&&\\
                a_{1n}& \cdots &\cdots& a_{nn}
            \end{pmatrix}
            \cdot
            \begin{pmatrix}
                \lambda_1\\
                \lambda_2\\
                \vdots\\
                \lambda_n
            \end{pmatrix}
            \ge 0 \; ; \; \forall \lambda \in \R^n
        \end{equation}
        $A$ será negativa si $\lambda A \lambda^t \ge 0 \; \text{ para todo } \lambda \in \R^n$\\\\
    % subsection matrices_definidas_positivas_y_negativas (end)
    \textbf{Criterio:}
    \begin{itemize}
        \item $A$ es definida positiva $\Leftrightarrow$ El determinante de todos los menores principales es positivo, es decir:
        \begin{equation}
            a_{11} \ge 0, \;
            \begin{vmatrix}
                a_{11}&a_{21}\\
                a_{12}&a_{22}
            \end{vmatrix}
            \ge 0, \;
            \begin{vmatrix}
                a_{11}&a_{21}&a_{31}\\
                a_{12}&a_{22}&a_{32}\\
                a_{13}&a_{23}&a_{33}
            \end{vmatrix}
            \ge 0, \; \cdots
        \end{equation}
        \item $A$ es definida negativa $\Leftrightarrow$ El determinante de los menores principales de orden $n$ es positivo si $n$ es par y negativo si $n$ es impar, es decir:
        \begin{equation}
            a_{11} \le 0, \;
            \begin{vmatrix}
                a_{11}&a_{21}\\
                a_{12}&a_{22}
            \end{vmatrix}
            \ge 0, \;
            \begin{vmatrix}
                a_{11}&a_{21}&a_{31}\\
                a_{12}&a_{22}&a_{32}\\
                a_{13}&a_{23}&a_{33}
            \end{vmatrix}
            \le 0, \; \cdots
        \end{equation}
    \end{itemize}

    \textbf{TEOREMA:}\textit{Sea $f:\R^n \rightarrow \R$ y $x_0 \in \R^n$ y $\nabla f(x_0) = (0,...,0)$}
    \begin{itemize}
        \item Si $Hess \; f(x_0)$ es estrictamente (sin iguales) definida positiva  $\Rightarrow x_0$ es un minimo relativo.
        \item Si $Hess \; f(x_0)$ es estrictamente (sin iguales) definida negativa $\Rightarrow x_0$ es un máximo relativo.
        \item Si $Hess \; f(x_0)$ no es definida negativa ni definida positiva $\Rightarrow x_0$ es un \textit{"punto de silla"}, es decir, hay direcciones en las que $x_0$ es un minimo y direcciones en las que es un máximo.
    \end{itemize}

    \subsection{Multiplicadores de Lagrange} % (fold)
    \label{sub:multiplicadores_de_lagrange}
    $f:\R^3 \rightarrow \R$ y sea $M = \{x \in \R^3\text{ tal que }g(x)= 0\}$(una superficie). Sea $x_0 \in M$ que es un máximo o mínimo relativo de $f$ en $M$ (es decir $f(x_0) \ge(\le) f(x)  \; ;\; \forall x \in M \text{ cercano a }x_0$). Entonces existes $\lambda \in \R$ tal que:
    \[\nabla(f - \lambda g)(x_0) = 0\]
    \textbf{Demostración:} Sea $x_0 \in M$ máximo relativo en $M$, entonces si $\gamma$ es una curva contenida en $M$ con $\gamma(0) = x_0$ tenemos:
    \[f \circ \gamma: \R \rightarrow \R \text{ tiene máximo en 0 }\]
    Por tanto:
    \[(f \circ \gamma)(0) = 0 \Rightarrow \nabla f(x_0) \cdot \gamma'(0) = 0\] 
    
    Por tanto para cualquier curva $\gamma$ contenida en $M$ tenemos $\nabla f(x_0)$ es perpendicular en $\gamma'(0)$ (vector tangente)

    Entonces $\nabla f(x_0)$ es normal a la superficie $M$ y sabemos que $\nabla g(x_0)$ es un vector normal a $M$, luego:
    \[\nabla f(x_0) = \lambda \nabla g(x_0) \text{ para un cierto número $\lambda$}\]

    \textbf{Ejemplo:} $f(x,y,z) = y^3 + xz^2$ Los extremos en la superficie $M = \{(x,y,z)\in \R^3 : x^2 + y^2 + z^2 = 1\}$. Tenemos $g(x,y,z) = x^2 + y^2 + z^2 - 1$. Por el teorema de Weierstrass, como $f$ es continua y $M$ es compacta, la función $f$ tiene un maximo y un mínimo en $M$. Empleando los multiplicadores de Lagrange:
    \[\nabla(f- \lambda g)=0 \Leftrightarrow (z^2, 3y^2,2xz)-\lambda2(x,y,z) = 0 \]
    Los puntos con los que estoy trabajando deben estar en la superficie, luego además de las tres ecuaciones que se derivan de la ecuación anterior obtenemos una cuarta:
    \begin{equation}
        \begin{cases}
            z^2 - 2\lambda x = 0\\
            3y^2 - 2\lambda y = 0\\
            2xz - 2 \lambda z = 0 \Leftrightarrow z(x-\lambda) = 0 \Leftrightarrow
            \begin{cases}
                z = 0 \Rightarrow 2\lambda x = 0 \Rightarrow
                \begin{cases}
                    \lambda = 0 \Rightarrow y = 0 \Rightarrow x = \pm 1 \rightarrow (\pm 1, 0, 0)\\
                    o\\
                    x = 0  \Rightarrow y = \pm 1 \; ; \; 3 - 2\lambda (\pm 1) = 0 \rightarrow (0, \pm 1, 0)
                \end{cases}\\
                o \\
                x = \lambda \Rightarrow
                \begin{cases}
                    z^2 - 2x^2 = 0 \Rightarrow z = \pm \sqrt{2} x\\
                    3y^2 -2xy = 0 \Rightarrow y(3y -2x) = 0 \Rightarrow
                    \begin{cases}    
                        y = 0\\
                        y = 2x/3
                    \end{cases}  
                \end{cases}
            \end{cases}\\
            x^2 + y^2 + z^2 -1 = 0
        \end{cases}
    \end{equation}
    Por tanto:
    \begin{equation}
        x^2 + y^2 + z^2 = 1 \Leftrightarrow \text{Candidatos de maximos y mínimos de $f$ en $M$} \Rightarrow
        \begin{cases}
            (1,0,0), (-1,0,0)\\
            (0,1,0), (0,-1,0)\\
            \cdots
        \end{cases}
    \end{equation}
    % subsection multiplicadores_de_lagrange (end)
    % section extremos_relativos (end)
    \section{Integración} % (fold)
    \label{sec:integración}
    Sea $f:\R \rightarrow \R$, entonces:
    \[\int_a^b f(x) \; dx = \lim_{max(\abs{x_{i+1}-x_i}) \to 0} \sum f(x_i)(x_{i+1} -x_i)\]

    Si trabajamos en más de 2 dimensiones funcionaría de la siguiente forma. Sea $f:\R^2 \rightarrow \R$ y sea $R \subset \R^2$ un rectángulo:
    \[\int_R f(x,y)\; dxdy = \text{volumen debajo de la gráfica $f(x,y)$ si $(x,y)\in R$}\]
    Sabemos que $R = \cup R_i$ donde $R_i$ son cuadrados. Entonces:
    \[\text{volumen debajo de la gráfica $f(x,y)$ si $(x,y)\in R$} = \lim_{diam(R_i)\to 0} \sum f(\text{Centro de }R_i,Area(R_i))\]
    ¿Y en el caso de que no sea un rectángulo? Tomamos que una forma $\Omega \subset R$ no es un rectángulo, y consideramos una función $g$ que vale $f$ si es un punto en $\Omega$ y 0 si no lo es. Luego:
    \[\int_\Omega f(x,y) \: dxdy = \int_R g(x,y) \; dxdy \]
    \subsection{Teorema de Fubini} % (fold)
    \label{sub:teorema_de_fubini}
        Sea $f:[a,b]\times[c,d] \rightarrow \R$ una función integrable, entonces:
        \[\int_{[a,b]\times[c,d]} f(x,y)\; dx dy = \int_a^b \left(\int_c^d f(x,y) dy\right)dx = \int_c^d \left(\int_a^b f(x,y) dx\right)dy\]
        De una forma más general, tomemos una forma $\Omega$ contenida dentro de un rectángulo $[a,b]\times[c,d]$. Definimos dos nuevos conjuntos de puntos
        \[S_x = \{y:(x,y) \in \Omega\}\]
        \[S_y = \{x:(x,y) \in \Omega\}\] 
        En este caso:
        \[\int_\Omega f(x,y) \; dxdy = \int_a^b \left(\int_{S_x} f(x,y) dy\right)dx = \int_c^d \left(\int_{S_y} f(x,y) dx\right)dy\]
    % subsection teorema_de_fubini (end)
    \subsection{Cambio de variable} % (fold)
    \label{sub:cambio_de_variable}
        Para funciones $f:\R\rightarrow \R$ tenemos:
        \[\int_a^b f(x) \; dx = \int_{g^{-1}(a)}^{g^{-1}(b)} f(g(t))\cdot g'(t) \; dt\]
        \underline{TCV}: Sea $g:\R^2 \rightarrow \R^2$ biyectiva y de la clase $C^1$. Sea $f:\R^2 \rightarrow \R$ integrable y sea $\Omega \subset \R^2$
        \[\int_\Omega f(x,y) \; dxdy = \int_{g^{-1}(\Omega)} f(g(u,v))\cdot Jg(u,v)\]
        \[Jg(u,v) = \text{determinante de }D_g(u,v)\text{ (matriz diferencial en $u$ y $v$)}\]
    % subsection cambio_de_variable (end)
    \subsection{Cambio a coordenadas polares} % (fold)
    \label{sub:cambio_a_coordenadas_polares}
        Si tomasemos una $\Omega$ que fuese facil de representar en coordenadas polaress podemo realizar un cambio a coordenadas polares, donde:
        \begin{align}
            \begin{cases}
              x &= rcos(\theta)\\
              y &= rsin(\theta)\\
              Jg &= 
              \begin{vmatrix}
                  cos(\theta)&-rsin(\theta)\\
                  sin(\theta)&rcos(\theta)
              \end{vmatrix} = rcos^2\theta + r sin^2\theta =  r 
            \end{cases} 
        \end{align}
        Tras esto, el cambio en la función sería:
        \[\int_\Omega f(x,y) \; dxdy =\int_{\theta_0}^{\theta_1}\left(\int_{r_0}^{r_1} f(rcos(\theta),rsin(\theta)) \cdot r \; dr\right) d\theta \]
    % subsection cambio_a_coordenadas_polares (end)
    \subsection{Cambio de Variable por integrales triples} % (fold)
    \label{sub:cambio_de_variable_por_integrales_triples}
        Sea $f:\R^3 \rightarrow \R$ y sea $\Phi:\R^3\rightarrow\R^2$ biyectiva. Sea $\Omega \subset \R^3$. Entonces:
        \[\int\int\int_{\Omega} f(x,y,z) dxdydz = \int \int \int_{\Phi^{-1}(\Omega)}f(\Phi(u,v,w))|J\Phi(u,v,w)| dudvdw  \]
    % subsection cambio_de_variable_por_integrales_triples (end)
    % section integración (end)
    \section{Cálculo vectorial} % (fold)
    \label{sec:cálculo_vectorial}
        \subsection{Teorema de Green} % (fold)
        \label{sub:teorema_de_green}
            Una curva $\gamma$ en $\R^n$ es $\gamma:[a,b] \rightarrow \R^n$. Cuando tenemos una curva, tenemos también un vector tangente. Este vector en un punto $\gamma(t)$ es $\gamma'(t)$
            \textbf{Definición:} Un campo vectorial en $\R^n$ es una aplicación $\vec{F}: \R^n\rightarrow \R^n$
            Por ejemplo:
            \[\vec{F}: \R^2 \rightarrow\R^2\]
            \[(x,y) \rightarrow (x,-y)\]
            De esta forma a cada punto $(x,y)$ se le está aplicando un vector $(x,-y)$.
            \textbf{Definición:} Sea una curva $\gamma$ en $\R^n$ y $\vec{F}$ un campo en $\R^n$, definimos:
            \[\int_{\gamma} \vec{F} = \int_a^b \vec{F}(\gamma(t))\cdot \gamma'(t) dt\]
            Por ejemplo, $\gamma$ es la parte superior del circulo unidad. $\vec{F}(x,y) = (x,-y)$:
            \[\gamma:\theta\in [0,\pi] \rightarrow (cos(\theta),sin(\theta))\]
            \[\gamma'(\theta)= (-sin(\theta),cos(\theta))\]
            \[\int_\gamma \vec{F} = \int_0^\pi \vec{F}(cos(\theta),sin(\theta)) \cdot (-sin(\theta),cos(\theta)) d\theta = \int_0^\pi (cos(\theta),-sin(\theta)) \cdot (-sin(\theta),cos(\theta)) d\theta = 0\]

            En este ámbito es importante conocer el concepto de \textbf{campos conservativo}. Un campo $\vec{F}$ se dice que es conservativo si existe una función $f$ tal que $\vec{F} = \vec{\nabla f}$ ($f$ se denomina el potencial).Observamos que si suponemos que $\vec{F}$ es un campo conservativo en $\R^2$:
            \[\vec{F} = (P,Q) = \left(\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}\right)\Rightarrow\begin{cases}
                P = \frac{\partial f}{\partial x}\\
                Q = \frac{\partial f}{\partial y}\\

            \end{cases}\Rightarrow \frac{\partial P}{\partial y} = \frac{\partial ^2 f}{\partial y \partial x} = \frac{\partial ^2 f}{\partial x \partial y} = \frac{\partial Q}{\partial x}\]
            Luego, obtenemos que
            \[\vec{F} = (P,Q) \Rightarrow \frac{\partial P}{\partial y} = \frac{\partial Q}{\partial x}\]
            \textbf{Ejercicio} ¿$\vec{F}(x,y)= (2xy - 3x^2, x^2 + 2y)$ es conservativo? $\Leftrightarrow \frac{\partial(2xy-3x^2)}{\partial y} = \frac{\partial(x^2 +2y)}{\partial x}$

            Queremos encontrar $f(x,y)$ tal que $\dfrac{\partial f}{\partial x} = 2xy-3x^2$ y $\dfrac{\partial f}{\partial y} = x^2-2y$. Tomamos:
            \[f(x,y) = \int (2xy-ex^2) dx + \phi(y) = x^2 y -x^3 + \phi(y)\]
            Encontraremos $\phi(y)$ tal que:
            \[x^2 + \phi'(y) = x^2 + 2y \Rightarrow \phi'(y) = 2y \Rightarrow \phi(y) = y^2 + C \]
            Luego la función potencial del campo $\vec{F}$ es:
            \[f(x,y) = x^2 y -x^3 + y^2 + C\] donde $C\in \R$ cualquiera.
            \textbf{Teorema:} Sea $\vec{F}$ un campo conservativo y $\gamma$ una curva cerrada ($\gamma(a) = \gamma(b)$). Entonces:
            \[\int_\gamma \vec{F} = 0\]
            \textbf{Demostración:}

                \begin{align}
                    \int_\gamma \vec{F} dt&= \int_a^b \vec{F}(\gamma(t)) \cdot \gamma'(t)dt \rightarrow \vec{F}(\gamma(t)) \cdot \gamma'(t) = \frac{d}{dt} \vec{F}(\gamma(t))\\
                    &= \int_a^b \frac{d}{dt} \vec{F}(\gamma(t)) = \vec{F}(\gamma(b)) - \vec{F}(\gamma(a)) = 0
                \end{align} 

        % subsection teorema_de_green (end)

    % section cálculo_vectorial (end)
\end{document}